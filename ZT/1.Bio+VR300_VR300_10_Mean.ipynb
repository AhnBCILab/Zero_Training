{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "through-turning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 7, 180)\n",
      "(210, 7, 180)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## train의 test값을 저장 한다. \n",
    "import hdf5storage\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import os\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs, Num[0]]\n",
    "\n",
    "def Balancing_DataSet(Epochs, size):\n",
    "        Epochs_New = np.zeros((size, Epochs.shape[1], Epochs.shape[2]))\n",
    "    \n",
    "        index = np.random.choice(Epochs.shape[0], size = size, replace = False)\n",
    "    \n",
    "        Epochs_New = Epochs[index, :, :]\n",
    "    \n",
    "        return Epochs_New\n",
    "        \n",
    "def Standardization(Epochs):\n",
    "        for i in range(Epochs.shape[1]):\n",
    "            Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "            Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "        return Epochs\n",
    "\n",
    "def plotGraph(filename):\n",
    "\n",
    "\n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        channelNames = mat['channelNames']\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq']\n",
    "        samplingFreq = samplingFreq[0,0]\n",
    "        stims = mat['stims']\n",
    "        channelNum = channelNames.shape\n",
    "        channelNum = channelNum[1]\n",
    "        eegData = np.transpose(eegData)\n",
    "\n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.23, 30, samplingFreq, order=4)\n",
    "    \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(0.6 * samplingFreq))\n",
    "        offset = int(np.floor(0.2 * samplingFreq)) \n",
    "        baseline = int(np.floor(0.8 * samplingFreq)) \n",
    "        [EpochsT, NumT] = Epoching(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching(eegData, stims, 0, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        EpochsN_New = Balancing_DataSet(EpochsN, NumT)\n",
    "        \n",
    "        EpochsT = Standardization(EpochsT)\n",
    "        EpochsN = Standardization(EpochsN_New)\n",
    "        Target_All=np.mean(EpochsT,axis=0)\n",
    "       \n",
    "        return [EpochsT[:,:,:], EpochsN[:,:,:]]\n",
    "\n",
    "\n",
    "def main():\n",
    "    #root = 'D:\\\\VR300Data\\\\0129\\\\Eunjin\\\\Training\\\\mat\\\\Training.mat'\n",
    "    root =  'D:\\\\VR300_20\\\\S08\\\\Training\\\\mat\\\\Training.mat'\n",
    "    T_all= np.zeros((210,7,180))\n",
    "    N_all= np.zeros((210,7,180))\n",
    "\n",
    "    [T_all[:,:,:],N_all[:,:,:]]=plotGraph(root)\n",
    "    mat_file = io.loadmat(root)\n",
    "    \n",
    "    target_data = T_all\n",
    "    non_target_data = N_all\n",
    "\n",
    "    print(target_data.shape)\n",
    "    print(non_target_data.shape)\n",
    "#-----------------------------------------\n",
    "    output_file = \"./resampled_data_test.npz\"\n",
    "    np.savez(output_file, np.array(target_data,dtype=float), np.array(non_target_data,dtype=float))\n",
    "#-------------------------------------\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "documentary-particle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1 is preprocessed\n",
      "subject 2 is preprocessed\n",
      "subject 3 is preprocessed\n",
      "subject 4 is preprocessed\n",
      "subject 5 is preprocessed\n",
      "subject 7 is preprocessed\n",
      "subject 8 is preprocessed\n",
      "subject 9 is preprocessed\n",
      "subject 10 is preprocessed\n",
      "subject 11 is preprocessed\n",
      "subject 12 is preprocessed\n",
      "subject 13 is preprocessed\n",
      "subject 14 is preprocessed\n",
      "subject 15 is preprocessed\n",
      "subject 16 is preprocessed\n",
      "subject 17 is preprocessed\n",
      "subject 18 is preprocessed\n",
      "subject 19 is preprocessed\n",
      "subject 20 is preprocessed\n",
      "subject 21 is preprocessed\n",
      "subject 22 is preprocessed\n",
      "subject 23 is preprocessed\n",
      "subject 24 is preprocessed\n",
      "subject 26 is preprocessed\n",
      "subject 27 is preprocessed\n",
      "subject 28 is preprocessed\n",
      "subject 29 is preprocessed\n",
      "subject 30 is preprocessed\n",
      "subject 31 is preprocessed\n",
      "subject 32 is preprocessed\n",
      "subject 33 is preprocessed\n",
      "subject 34 is preprocessed\n",
      "subject 35 is preprocessed\n",
      "subject 36 is preprocessed\n",
      "subject 37 is preprocessed\n",
      "subject 39 is preprocessed\n",
      "subject 40 is preprocessed\n",
      "subject 41 is preprocessed\n",
      "subject 42 is preprocessed\n",
      "subject 43 is preprocessed\n",
      "subject 45 is preprocessed\n",
      "subject 46 is preprocessed\n",
      "subject 47 is preprocessed\n",
      "subject 48 is preprocessed\n",
      "subject 49 is preprocessed\n",
      "subject 50 is preprocessed\n",
      "subject 51 is preprocessed\n",
      "subject 54 is preprocessed\n",
      "subject 55 is preprocessed\n"
     ]
    }
   ],
   "source": [
    "# DataProcessing and model generation process\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import hdf5storage\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import os,glob\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def Re_referencing(eegData, channelNum, sampleNum):\n",
    "        after_car = np.zeros((channelNum,sampleNum))\n",
    "        for i in np.arange(channelNum):\n",
    "            after_car[i,:] = eegData[i,:] - np.mean(eegData,axis=0)\n",
    "        return after_car\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "def Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, componentNum):\n",
    "    NumT_Aver = NumT-componentNum\n",
    "    NumN_Aver = NumN-componentNum\n",
    "    \n",
    "    EpochsT_Aver = np.zeros((NumT_Aver, channelNum, epochSampleNum))\n",
    "    EpochsN_Aver = np.zeros((NumN_Aver, channelNum, epochSampleNum))\n",
    "    for i in range(NumT_Aver):\n",
    "        EpochsT_Aver[i, :, :] = np.mean(EpochsT[i:i+componentNum, :, :], axis=0)\n",
    "    for j in range(NumN_Aver):\n",
    "        EpochsN_Aver[j, :, :] = np.mean(EpochsN[j:j+componentNum, :, :], axis=0)\n",
    "        \n",
    "    return [EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver]\n",
    "\n",
    "\n",
    "def Epoching(eegData, stims, samplingFreq, channelNum, epochSampleNum, offset, baseline):\n",
    "        Time_after = np.add(stims,offset).astype(int)\n",
    "        Time_base = np.add(stims,baseline).astype(int)\n",
    "        Num = stims.shape[1]\n",
    "        Epochs = np.zeros((Num, channelNum, epochSampleNum))\n",
    "        for j in range(Num):\n",
    "            Epochs[j, :, :] = eegData[:,Time_after[0][j]:Time_after[0][j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs,Num]\n",
    "\n",
    "\n",
    "def resampling(Epochs, EpochNum, resampleRate, channelNum):\n",
    "        resampled_epoch = np.zeros((EpochNum, channelNum, resampleRate))\n",
    "        for i in range(EpochNum):\n",
    "            for j in range(channelNum):\n",
    "                resampled_epoch[i,j,:] = signal.resample(Epochs[i,j,:], resampleRate)\n",
    "        return resampled_epoch\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def Epoching_d(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs, Num[0]]\n",
    "\n",
    "def Convert_to_featureVector(EpochsT, NumT, EpochsN, NumN, featureNum):\n",
    "        FeaturesT = np.zeros((NumT, featureNum))\n",
    "        for i in range(NumT):\n",
    "            FeaturesT[i,:] = np.reshape(EpochsT[i,:,:],(1,featureNum))\n",
    "        FeaturesN = np.zeros((NumN, featureNum))\n",
    "        for j in range(NumN):\n",
    "            FeaturesN[j,:] = np.reshape(EpochsN[j,:,:],(1,featureNum))\n",
    "        return [FeaturesT,FeaturesN]\n",
    "\n",
    "\n",
    "def Balancing_DataSet(Epochs, size):\n",
    "        Epochs_New = np.zeros((size, Epochs.shape[1], Epochs.shape[2]))\n",
    "    \n",
    "        index = np.random.choice(Epochs.shape[0], size = size, replace = False)\n",
    "    \n",
    "        Epochs_New = Epochs[index, :, :]\n",
    "    \n",
    "        return Epochs_New\n",
    "    \n",
    "def Standardization(Epochs):\n",
    "        for i in range(Epochs.shape[1]):\n",
    "            Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "            Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "        return Epochs\n",
    "    \n",
    "def baseline_correction(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        for j in range(Epochs.shape[0]):\n",
    "            Epochs[j,i,:] = np.subtract(Epochs[j,i,:], np.mean(Epochs[j,i,:]))\n",
    "    \n",
    "    return Epochs\n",
    "def Make_Average_Component_d(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, componentNum):\n",
    "        EpochsT = Standardization(EpochsT)\n",
    "        EpochsN = Standardization(EpochsN)\n",
    "        NumT_Aver = NumT-componentNum\n",
    "        NumN_Aver = NumN-componentNum\n",
    "    \n",
    "        EpochsT_Aver = np.zeros((NumT_Aver, channelNum, epochSampleNum))\n",
    "        EpochsN_Aver = np.zeros((NumN_Aver, channelNum, epochSampleNum))\n",
    "        for i in range(NumT_Aver):\n",
    "            EpochsT_Aver[i, :, :] = np.mean(EpochsT[i:i+componentNum, :, :], axis=0)\n",
    "        for j in range(NumN_Aver):\n",
    "            EpochsN_Aver[j, :, :] = np.mean(EpochsN[j:j+componentNum, :, :], axis=0)\n",
    "        \n",
    "        return [EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver]\n",
    "\n",
    "def plotGraph_v(filename):\n",
    "\n",
    "\n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        channelNames = mat['channelNames']\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq']\n",
    "        samplingFreq = samplingFreq[0,0]\n",
    "        stims = mat['stims']\n",
    "        channelNum = channelNames.shape\n",
    "        channelNum = channelNum[1]\n",
    "        eegData = np.transpose(eegData)\n",
    "        \n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.23, 30, samplingFreq, order=4)\n",
    "    \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(0.6 * samplingFreq))\n",
    "        offset = int(np.floor(0.2 * samplingFreq)) \n",
    "        baseline = int(np.floor(0.8 * samplingFreq)) \n",
    "        [EpochsT, NumT] = Epoching_d(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching_d(eegData, stims, 0, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        EpochsN_New = Balancing_DataSet(EpochsN, NumT)\n",
    "        \n",
    "        #Convert to feature vector\n",
    "        EpochsT = Standardization(EpochsT)\n",
    "        EpochsN = Standardization(EpochsN_New)\n",
    "        Target_All=np.mean(EpochsT,axis=0)\n",
    "\n",
    "        return [EpochsT[:,:,:], EpochsN[:,:,:]]    \n",
    "def plotGraph_b(filename):\n",
    "        channelNum = 7\n",
    "        epochSampleNum = 512\n",
    "        epochNum = 150\n",
    "        resampleRate = 300\n",
    "        target = np.zeros((epochNum,1,resampleRate))\n",
    "        nontarget = np.zeros((epochNum,1,resampleRate))\n",
    "\n",
    "\n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq'][0,0]\n",
    "        stimsN = mat['stimsN']\n",
    "        stimsT = mat['stimsT']\n",
    "        sampleNum = eegData.shape[1]\n",
    "        channelIndex = [18, 30, 12, 11, 19, 10, 15]\n",
    "            \n",
    "            # vr300 7 channel\n",
    "            # [P4, Fz, Pz, P3, PO8, PO7, Oz]\n",
    "            # [19, 31, 13, 12, 20, 11, 16]\n",
    "            \n",
    "        eegData = eegData[channelIndex]\n",
    "            \n",
    "            ## Preprocessing process\n",
    "        eegData = Re_referencing(eegData, channelNum, eegData.shape[1])\n",
    "            \n",
    "            #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.23, 30, samplingFreq, 4)\n",
    "        \n",
    "#             #Epoching\n",
    "        epochSampleNum = int(np.floor(1 * samplingFreq))\n",
    "        offset = int(np.floor(0 * samplingFreq))\n",
    "        baseline = int(np.floor(1 * samplingFreq))\n",
    "        [EpochsT, NumT] = Epoching(eegData, stimsT, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching(eegData, stimsN, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        NumN = NumT\n",
    "        EpochsN = Balancing_DataSet(EpochsN, NumN)\n",
    "        \n",
    "        EpochsT = Standardization(EpochsT)\n",
    "        EpochsN = Standardization(EpochsN)\n",
    "        EpochsT_Aver = resampling(EpochsT, NumT, resampleRate, channelNum) \n",
    "        EpochsN_Aver = resampling(EpochsN, NumN, resampleRate, channelNum)\n",
    "\n",
    "        \n",
    "        return [EpochsT_Aver, EpochsN_Aver]\n",
    "def main():\n",
    "    hz=180   \n",
    "    \n",
    "    \n",
    " #--------------------------------------------------------------    \n",
    "    root = 'D:\\\\VR300_20\\\\S'\n",
    "    T_all_V= np.zeros((17*210,7,hz))\n",
    "    N_all_V= np.zeros((17*210,7,hz))\n",
    "    count = 0\n",
    "        \n",
    "    for i in np.arange(1,20):\n",
    "        if(i==7 or i==13 or i==16): continue\n",
    "        if(i<10):\n",
    "            count = count + 1\n",
    "            root_VR = root + '0' + str(i)+'/Training/mat/'\n",
    "            current_list = sorted(glob.glob(root_VR + '*.mat'), key=os.path.getmtime, reverse=True)\n",
    "            root_VR = current_list[0]\n",
    "        else:\n",
    "            count = count + 1\n",
    "            root_VR = root + str(i)+'/Training/mat/'\n",
    "            current_list = sorted(glob.glob(root_VR + '*.mat'), key=os.path.getmtime, reverse=True)\n",
    "            root_VR = current_list[0]\n",
    "        [T_all_V[210*(count-1):210*count,:,:],N_all_V[210*(count-1):210*count,:,:]]=plotGraph_v(root_VR)\n",
    "#-------------------------------------------------------\n",
    "\n",
    "    filename = ''\n",
    "    channelNum = 7 # (n_components)\n",
    "    epochSampleNum = 300\n",
    "    epochNum = 150\n",
    "    epochNum_N = 150\n",
    "    subject_num = []\n",
    "    root = 'D:\\\\P300_biosemi_55\\\\S'\n",
    "    T_all = np.zeros((epochNum*49,channelNum,hz))\n",
    "    N_all = np.zeros((epochNum_N*49,channelNum,hz))\n",
    "    count =0\n",
    "    \n",
    "    co = np.zeros((49,7))\n",
    "    \n",
    "    for l in np.arange(1,56):\n",
    "        if(l==25 or l==44 or l==53 or l==6 or l==38 or l==52): \n",
    "            continue\n",
    "        if(l<10):\n",
    "            count = count + 1\n",
    "            filename = root + '0' + str(l)\n",
    "        else:\n",
    "            count = count +1\n",
    "            filename = root + str(l)\n",
    "        T_all_b= np.zeros((epochNum,7,epochSampleNum))\n",
    "        N_all_b= np.zeros((epochNum_N,7,epochSampleNum))\n",
    "        \n",
    "        [T_all_b[:,:,:],N_all_b[:,:,:]]=plotGraph_b(filename)\n",
    "        \n",
    "        Target_All=np.mean(T_all_V,axis=0)\n",
    "        target_data_b = np.mean(T_all_b, axis=0)\n",
    "        \n",
    "        mat = np.zeros((2, hz))\n",
    "        for j in np.arange(0,7):\n",
    "            mat[0] = Target_All[j,:]\n",
    "            coef = np.zeros(75)\n",
    "            for b in np.arange(0,75):\n",
    "                mat[1] = target_data_b[j,0*hz+1*b:1*hz+1*(b)]\n",
    "                corrcoef = np.corrcoef(mat)\n",
    "                coef[b] = corrcoef[0,1]\n",
    "            index = np.argmax(np.abs(coef))\n",
    "            co[count-1,j] = coef[index]\n",
    "            #print('index:')\n",
    "            #print(index)\n",
    "            \n",
    "        #biosemi 맞춰주기\n",
    "            start = 0*hz+1*index\n",
    "            finish = 1*hz+1*(index)\n",
    "        \n",
    "            T_all_b[:,j,0:hz] = T_all_b[:,j,start:finish]\n",
    "            N_all_b[:,j,0:hz] = N_all_b[:,j,start:finish]\n",
    "            T_all_mean = np.mean(T_all_b, axis=0)\n",
    "            if coef[index] < 0:\n",
    "                T_all_b[:,j,0:hz] = T_all_b[:,j,0:hz]*(-1)\n",
    "                T_all_mean = np.mean(T_all_b, axis=0)\n",
    "                #print('inverse')\n",
    "            \n",
    "        #높이 맞추기\n",
    "            #print(max(mat[0]))\n",
    "            #print(max(T_all_mean[j,:]))\n",
    "            rate=max(mat[0])/max(T_all_mean[j,:])\n",
    "            T_all_b[:,j,0:hz] = T_all_b[:,j,0:hz]*rate\n",
    "            N_all_b[:,j,0:hz] = N_all_b[:,j,0:hz]*rate\n",
    "        \n",
    "\n",
    "        [T_all[epochNum*(count-1):epochNum*count,:,:],N_all[epochNum_N*(count-1):epochNum_N*count,:,:]] = [T_all_b[:,:,0:hz],N_all_b[:,:,0:hz]]\n",
    "        print(\"subject {0} is preprocessed\".format(str(l)))\n",
    "    \n",
    "\n",
    "    \n",
    "    tdata = np.concatenate((T_all[:,:,:],T_all_V[:,:,:]),axis=0)\n",
    "    ntdata = np.concatenate((N_all[:,:,:],N_all_V[:,:,:]),axis =0)\n",
    "     \n",
    "#-----------------------------------------\n",
    "    output_file = \"./resampled_data_Bio_correlation_1.npz\"\n",
    "    np.savez(output_file, np.array(tdata,dtype=float), np.array(ntdata,dtype=float))\n",
    "#-------------------------------------\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bound-merchant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n",
      "Target data shape:  (10920, 7, 180)\n",
      "Non-target data shape:  (10920, 7, 180)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfile2 = \"./resampled_data_test.npz\"\\nnpzfile2 = np.load(file2)\\nprint(npzfile2.files)\\n\\ntest_data = npzfile2[\\'arr_0\\']\\nnon_test_data = npzfile2[\\'arr_1\\']\\n\\nprint(\"Target data shape: \", test_data.shape)\\nprint(\"Non-target data shape: \", non_test_data.shape)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = \"./resampled_data_Bio_correlation_1.npz\"\n",
    "npzfile = np.load(filename)\n",
    "print(npzfile.files)\n",
    "\n",
    "target_data = npzfile['arr_0']\n",
    "non_target_data = npzfile['arr_1']\n",
    "\n",
    "print(\"Target data shape: \", target_data.shape)\n",
    "print(\"Non-target data shape: \", non_target_data.shape)\n",
    "'''\n",
    "file2 = \"./resampled_data_test.npz\"\n",
    "npzfile2 = np.load(file2)\n",
    "print(npzfile2.files)\n",
    "\n",
    "test_data = npzfile2['arr_0']\n",
    "non_test_data = npzfile2['arr_1']\n",
    "\n",
    "print(\"Target data shape: \", test_data.shape)\n",
    "print(\"Non-target data shape: \", non_test_data.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "suited-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (16380, 7, 180)\n",
      "Y_train shape:  (16380,)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "X_test shape:  (5460, 7, 180)\n",
      "y_test shape:  (5460,)\n",
      "[1. 0. 1. ... 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "'''\n",
    "X_train = np.concatenate([target_data, non_target_data])\n",
    "y_train = np.concatenate([np.ones(target_data.shape[0]), np.zeros(non_target_data.shape[0])])\n",
    "X_test = np.concatenate([test_data, non_test_data])\n",
    "y_test = np.concatenate([np.ones(test_data.shape[0]), np.zeros(non_test_data.shape[0])])\n",
    "'''\n",
    "\n",
    "X = np.concatenate([target_data, non_target_data])\n",
    "y = np.concatenate([np.ones(target_data.shape[0]), np.zeros(non_target_data.shape[0])])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=777)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", y_train.shape)\n",
    "print(y_train)\n",
    "print(\"\\nX_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "balanced-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "empirical-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        conv1 = nn.Conv1d(7, 3, 3, 1, padding=True) # 1, 6 은 임의로 한것\n",
    "        max_pool = nn.MaxPool1d(4)\n",
    "        self.bn1 = nn.BatchNorm1d(3)\n",
    "        fc1 = nn.Linear(3*1*45, 2) # fully connected layer 1번 \n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            conv1,  # N x 7 x 180 -> N x 3 x 180\n",
    "            self.bn1,\n",
    "            nn.ReLU(),\n",
    "            max_pool  # N x 3 x 180 -> N x 3 x 45\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            fc1,  # N x 1024 -> N x 32\n",
    "            nn.Softmax()  # 이건 분류 할때 사용 한거  out 이 1개일땐 다른거 쓰면 \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        dim = 1\n",
    "        for d in x.size()[1:]: #  N x 16 x 1 x 128\n",
    "            dim = dim * d\n",
    "            \n",
    "        x = x.view(-1, dim)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "yellow-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EEGDataset import EEGDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "                EEGDataset(X_train, y_train), \n",
    "                batch_size=batch_size, \n",
    "                shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "                EEGDataset(X_test, y_test),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "diagnostic-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 1e-5\n",
    "# 더 천천히 모델은 분석 하는것 \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) # Adam optimizer -->내려가는 방법 생각해보기 == lr learning mate 적절하게 하면 좋다. adam 은 0.001 줄여보면서 \n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "parliamentary-output",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/20 | step: 1000/4095 | train_loss: 0.7405 | test_loss: 0.7299 | acc: 0.5018\n",
      "epoch: 1/20 | step: 2000/4095 | train_loss: 0.7310 | test_loss: 0.7242 | acc: 0.5079\n",
      "epoch: 1/20 | step: 3000/4095 | train_loss: 0.7263 | test_loss: 0.7197 | acc: 0.5143\n",
      "epoch: 1/20 | step: 4000/4095 | train_loss: 0.7126 | test_loss: 0.7166 | acc: 0.5176\n",
      "epoch: 2/20 | step: 1000/4095 | train_loss: 0.7197 | test_loss: 0.7128 | acc: 0.5198\n",
      "epoch: 2/20 | step: 2000/4095 | train_loss: 0.7112 | test_loss: 0.7101 | acc: 0.5227\n",
      "epoch: 2/20 | step: 3000/4095 | train_loss: 0.7115 | test_loss: 0.7076 | acc: 0.5233\n",
      "epoch: 2/20 | step: 4000/4095 | train_loss: 0.7099 | test_loss: 0.7056 | acc: 0.5258\n",
      "epoch: 3/20 | step: 1000/4095 | train_loss: 0.7070 | test_loss: 0.7031 | acc: 0.5260\n",
      "epoch: 3/20 | step: 2000/4095 | train_loss: 0.7087 | test_loss: 0.7013 | acc: 0.5260\n",
      "epoch: 3/20 | step: 3000/4095 | train_loss: 0.6968 | test_loss: 0.6995 | acc: 0.5277\n",
      "epoch: 3/20 | step: 4000/4095 | train_loss: 0.6981 | test_loss: 0.6979 | acc: 0.5280\n",
      "epoch: 4/20 | step: 1000/4095 | train_loss: 0.6951 | test_loss: 0.6961 | acc: 0.5300\n",
      "epoch: 4/20 | step: 2000/4095 | train_loss: 0.7023 | test_loss: 0.6944 | acc: 0.5317\n",
      "epoch: 4/20 | step: 3000/4095 | train_loss: 0.6954 | test_loss: 0.6928 | acc: 0.5335\n",
      "epoch: 4/20 | step: 4000/4095 | train_loss: 0.6962 | test_loss: 0.6916 | acc: 0.5385\n",
      "epoch: 5/20 | step: 1000/4095 | train_loss: 0.6904 | test_loss: 0.6901 | acc: 0.5414\n",
      "epoch: 5/20 | step: 2000/4095 | train_loss: 0.6873 | test_loss: 0.6887 | acc: 0.5440\n",
      "epoch: 5/20 | step: 3000/4095 | train_loss: 0.6907 | test_loss: 0.6873 | acc: 0.5493\n",
      "epoch: 5/20 | step: 4000/4095 | train_loss: 0.6946 | test_loss: 0.6858 | acc: 0.5500\n",
      "epoch: 6/20 | step: 1000/4095 | train_loss: 0.6875 | test_loss: 0.6845 | acc: 0.5568\n",
      "epoch: 6/20 | step: 2000/4095 | train_loss: 0.6876 | test_loss: 0.6831 | acc: 0.5549\n",
      "epoch: 6/20 | step: 3000/4095 | train_loss: 0.6842 | test_loss: 0.6818 | acc: 0.5599\n",
      "epoch: 6/20 | step: 4000/4095 | train_loss: 0.6811 | test_loss: 0.6804 | acc: 0.5621\n",
      "epoch: 7/20 | step: 1000/4095 | train_loss: 0.6787 | test_loss: 0.6790 | acc: 0.5659\n",
      "epoch: 7/20 | step: 2000/4095 | train_loss: 0.6809 | test_loss: 0.6777 | acc: 0.5676\n",
      "epoch: 7/20 | step: 3000/4095 | train_loss: 0.6806 | test_loss: 0.6765 | acc: 0.5696\n",
      "epoch: 7/20 | step: 4000/4095 | train_loss: 0.6814 | test_loss: 0.6751 | acc: 0.5722\n",
      "epoch: 8/20 | step: 1000/4095 | train_loss: 0.6746 | test_loss: 0.6737 | acc: 0.5771\n",
      "epoch: 8/20 | step: 2000/4095 | train_loss: 0.6707 | test_loss: 0.6724 | acc: 0.5821\n",
      "epoch: 8/20 | step: 3000/4095 | train_loss: 0.6714 | test_loss: 0.6712 | acc: 0.5839\n",
      "epoch: 8/20 | step: 4000/4095 | train_loss: 0.6824 | test_loss: 0.6701 | acc: 0.5866\n",
      "epoch: 9/20 | step: 1000/4095 | train_loss: 0.6724 | test_loss: 0.6691 | acc: 0.5870\n",
      "epoch: 9/20 | step: 2000/4095 | train_loss: 0.6688 | test_loss: 0.6678 | acc: 0.5914\n",
      "epoch: 9/20 | step: 3000/4095 | train_loss: 0.6707 | test_loss: 0.6666 | acc: 0.5940\n",
      "epoch: 9/20 | step: 4000/4095 | train_loss: 0.6724 | test_loss: 0.6654 | acc: 0.5995\n",
      "epoch: 10/20 | step: 1000/4095 | train_loss: 0.6717 | test_loss: 0.6643 | acc: 0.6005\n",
      "epoch: 10/20 | step: 2000/4095 | train_loss: 0.6685 | test_loss: 0.6632 | acc: 0.6024\n",
      "epoch: 10/20 | step: 3000/4095 | train_loss: 0.6640 | test_loss: 0.6622 | acc: 0.6027\n",
      "epoch: 10/20 | step: 4000/4095 | train_loss: 0.6671 | test_loss: 0.6614 | acc: 0.6055\n",
      "epoch: 11/20 | step: 1000/4095 | train_loss: 0.6609 | test_loss: 0.6604 | acc: 0.6079\n",
      "epoch: 11/20 | step: 2000/4095 | train_loss: 0.6614 | test_loss: 0.6596 | acc: 0.6082\n",
      "epoch: 11/20 | step: 3000/4095 | train_loss: 0.6618 | test_loss: 0.6584 | acc: 0.6104\n",
      "epoch: 11/20 | step: 4000/4095 | train_loss: 0.6615 | test_loss: 0.6576 | acc: 0.6099\n",
      "epoch: 12/20 | step: 1000/4095 | train_loss: 0.6603 | test_loss: 0.6566 | acc: 0.6126\n",
      "epoch: 12/20 | step: 2000/4095 | train_loss: 0.6603 | test_loss: 0.6559 | acc: 0.6121\n",
      "epoch: 12/20 | step: 3000/4095 | train_loss: 0.6600 | test_loss: 0.6552 | acc: 0.6145\n",
      "epoch: 12/20 | step: 4000/4095 | train_loss: 0.6540 | test_loss: 0.6543 | acc: 0.6168\n",
      "epoch: 13/20 | step: 1000/4095 | train_loss: 0.6637 | test_loss: 0.6535 | acc: 0.6172\n",
      "epoch: 13/20 | step: 2000/4095 | train_loss: 0.6579 | test_loss: 0.6529 | acc: 0.6200\n",
      "epoch: 13/20 | step: 3000/4095 | train_loss: 0.6560 | test_loss: 0.6522 | acc: 0.6220\n",
      "epoch: 13/20 | step: 4000/4095 | train_loss: 0.6525 | test_loss: 0.6516 | acc: 0.6225\n",
      "epoch: 14/20 | step: 1000/4095 | train_loss: 0.6539 | test_loss: 0.6510 | acc: 0.6223\n",
      "epoch: 14/20 | step: 2000/4095 | train_loss: 0.6619 | test_loss: 0.6505 | acc: 0.6256\n",
      "epoch: 14/20 | step: 3000/4095 | train_loss: 0.6495 | test_loss: 0.6500 | acc: 0.6267\n",
      "epoch: 14/20 | step: 4000/4095 | train_loss: 0.6560 | test_loss: 0.6494 | acc: 0.6260\n",
      "epoch: 15/20 | step: 1000/4095 | train_loss: 0.6467 | test_loss: 0.6488 | acc: 0.6269\n",
      "epoch: 15/20 | step: 2000/4095 | train_loss: 0.6587 | test_loss: 0.6483 | acc: 0.6288\n",
      "epoch: 15/20 | step: 3000/4095 | train_loss: 0.6538 | test_loss: 0.6479 | acc: 0.6284\n",
      "epoch: 15/20 | step: 4000/4095 | train_loss: 0.6534 | test_loss: 0.6474 | acc: 0.6319\n",
      "epoch: 16/20 | step: 1000/4095 | train_loss: 0.6484 | test_loss: 0.6470 | acc: 0.6319\n",
      "epoch: 16/20 | step: 2000/4095 | train_loss: 0.6554 | test_loss: 0.6467 | acc: 0.6304\n",
      "epoch: 16/20 | step: 3000/4095 | train_loss: 0.6523 | test_loss: 0.6461 | acc: 0.6321\n",
      "epoch: 16/20 | step: 4000/4095 | train_loss: 0.6457 | test_loss: 0.6458 | acc: 0.6352\n",
      "epoch: 17/20 | step: 1000/4095 | train_loss: 0.6531 | test_loss: 0.6454 | acc: 0.6364\n",
      "epoch: 17/20 | step: 2000/4095 | train_loss: 0.6489 | test_loss: 0.6451 | acc: 0.6352\n",
      "epoch: 17/20 | step: 3000/4095 | train_loss: 0.6502 | test_loss: 0.6449 | acc: 0.6363\n",
      "epoch: 17/20 | step: 4000/4095 | train_loss: 0.6453 | test_loss: 0.6444 | acc: 0.6368\n",
      "epoch: 18/20 | step: 1000/4095 | train_loss: 0.6478 | test_loss: 0.6441 | acc: 0.6375\n",
      "epoch: 18/20 | step: 2000/4095 | train_loss: 0.6441 | test_loss: 0.6437 | acc: 0.6375\n",
      "epoch: 18/20 | step: 3000/4095 | train_loss: 0.6503 | test_loss: 0.6434 | acc: 0.6370\n",
      "epoch: 18/20 | step: 4000/4095 | train_loss: 0.6523 | test_loss: 0.6431 | acc: 0.6366\n",
      "epoch: 19/20 | step: 1000/4095 | train_loss: 0.6442 | test_loss: 0.6428 | acc: 0.6381\n",
      "epoch: 19/20 | step: 2000/4095 | train_loss: 0.6444 | test_loss: 0.6425 | acc: 0.6368\n",
      "epoch: 19/20 | step: 3000/4095 | train_loss: 0.6515 | test_loss: 0.6425 | acc: 0.6361\n",
      "epoch: 19/20 | step: 4000/4095 | train_loss: 0.6458 | test_loss: 0.6420 | acc: 0.6383\n",
      "epoch: 20/20 | step: 1000/4095 | train_loss: 0.6483 | test_loss: 0.6417 | acc: 0.6394\n",
      "epoch: 20/20 | step: 2000/4095 | train_loss: 0.6450 | test_loss: 0.6414 | acc: 0.6401\n",
      "epoch: 20/20 | step: 3000/4095 | train_loss: 0.6481 | test_loss: 0.6411 | acc: 0.6401\n",
      "epoch: 20/20 | step: 4000/4095 | train_loss: 0.6461 | test_loss: 0.6409 | acc: 0.6408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "num_batches = len(train_loader)\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \"\"\" \n",
    "        이번 학습에 사용될 데이터를 Batch 단위로 불러옵니다.\n",
    "        우리는 이전에 batch_size를 4로 설정했으므로, 4개의 데이터가 불러와집니다.\n",
    "        \"\"\"\n",
    "\n",
    "        data, label = data['data'].float().to(DEVICE), data['labels'].float().to(DEVICE)\n",
    "        \"\"\"\n",
    "        optimizer.zero_grad(): 함수를 사용하여 기존에 남아있던 gradient를 모두 제거해줍니다.\n",
    "        이는 이전 데이터가 새로 학습될 데이터에 영향을 끼치는 것을 막아줍니다.\n",
    "        \n",
    "        output = model(data): CNN 모델에 학습 데이터를 넣고 결과를 만들어냅니다.\n",
    "        \n",
    "        loss = criterion(output, label): 모델이 만들어낸 결과와, 실제 정답간의 차이를 이용해서 오차 값을 만들어 냅니다.\n",
    "        추후에 이 값을 이용하여 모델이 학습을 하게 됩니다.\n",
    "        \n",
    "        loss.backward(): 위에서 만들어낸 오차 값을 각 노드에게 전파하여 각 노드가 업데이트 해야 할 오차가 얼마인지 찾아냅니다.\n",
    "        \n",
    "        optimizer.stop(): 각 노드별로 받은 오차를 가지고 optimizer의 방법 (여기서는 Adam)을 기반으로 weight를 업데이트 합니다.\n",
    "        \"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Visualization을 위해 loss값과 accuracy를 저장합니다.\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_score(np.argmax(label.cpu().detach().numpy(), axis=1), np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "        \n",
    "        \"\"\"\n",
    "        10번의 batch마다 test를 진행합니다.\n",
    "        모델을 test할 때는 weight를 업데이트 시키면 안되기 때문에 torch.no_grad()를 이용합니다.\n",
    "        freconnected --> deep learning transfer learning \n",
    "        \"\"\"\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                for j, test_data in enumerate(test_loader):\n",
    "                    test_data, test_label = test_data['data'].float().to(DEVICE), test_data['labels'].float().to(DEVICE)\n",
    "                    test_output = model(test_data)\n",
    "                    loss = criterion(test_output, test_label)\n",
    "                    \n",
    "                    test_loss += loss.item()\n",
    "                    test_acc += accuracy_score(np.argmax(test_label.cpu().detach().numpy(), axis=1), np.argmax(test_output.cpu().detach().numpy(), axis=1))\n",
    "            \n",
    "            print('epoch: {}/{} | step: {}/{} | train_loss: {:.4f} | test_loss: {:.4f} | acc: {:.4f}'.format(\n",
    "                epoch + 1, epochs, i + 1, num_batches, train_loss / 1000, test_loss / len(test_loader), test_acc / len(test_loader)\n",
    "            ))\n",
    "            \n",
    "            train_loss_list.append(train_loss / 1000)\n",
    "            train_acc_list.append(train_acc / 1000)\n",
    "            test_loss_list.append(test_loss / len(test_loader))\n",
    "            test_acc_list.append(test_acc / len(test_loader))\n",
    "            train_loss = 0\n",
    "            train_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coral-election",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x210f7cdfc50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_tick = np.arange(0, len(train_loss_list) * 10, 10)\n",
    "plt.title('Loss graph')\n",
    "plt.plot(x_tick, train_loss_list, label='Train')\n",
    "plt.plot(x_tick, test_loss_list, label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wrapped-wealth",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x210f7d5bac8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_tick = np.arange(0, len(train_acc_list) * 10, 10)\n",
    "plt.title('Accuracy graph')\n",
    "plt.plot(x_tick, train_acc_list, label='Train')\n",
    "plt.plot(x_tick, test_acc_list, label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unexpected-master",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (bn1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(7, 3, kernel_size=(3,), stride=(1,), padding=(True,))\n",
       "    (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=135, out_features=2, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save='D:/P300_biosemi_55/Model/Bio/ZERO_Bio.pt'\n",
    "model_save_weights='D:/P300_biosemi_55/Model/Bio/Weight/ZERO_Weight_Bio.pt'\n",
    "\n",
    "torch.save(model, model_save)\n",
    "torch.save(model.state_dict(), model_save_weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pursuant-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5925, 0.4075],\n",
      "        [0.4051, 0.5949],\n",
      "        [0.3591, 0.6409],\n",
      "        [0.5059, 0.4941],\n",
      "        [0.4667, 0.5333],\n",
      "        [0.3704, 0.6296],\n",
      "        [0.5423, 0.4577]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  5 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.5080, 0.4920],\n",
      "        [0.2031, 0.7969],\n",
      "        [0.3799, 0.6201],\n",
      "        [0.6674, 0.3326],\n",
      "        [0.5923, 0.4077],\n",
      "        [0.5994, 0.4006],\n",
      "        [0.5291, 0.4709]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.1934, 0.8066],\n",
      "        [0.6920, 0.3080],\n",
      "        [0.2949, 0.7051],\n",
      "        [0.7339, 0.2661],\n",
      "        [0.4470, 0.5530],\n",
      "        [0.6362, 0.3638],\n",
      "        [0.3706, 0.6294]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4809, 0.5191],\n",
      "        [0.3014, 0.6986],\n",
      "        [0.3313, 0.6687],\n",
      "        [0.2296, 0.7704],\n",
      "        [0.6078, 0.3922],\n",
      "        [0.6432, 0.3568],\n",
      "        [0.6589, 0.3411]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(4, device='cuda:0')\n",
      "tensor([[0.4750, 0.5250],\n",
      "        [0.5233, 0.4767],\n",
      "        [0.5925, 0.4075],\n",
      "        [0.6000, 0.4000],\n",
      "        [0.6539, 0.3461],\n",
      "        [0.5827, 0.4173],\n",
      "        [0.5459, 0.4541]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  7 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.6317, 0.3683],\n",
      "        [0.6784, 0.3216],\n",
      "        [0.5104, 0.4896],\n",
      "        [0.5062, 0.4938],\n",
      "        [0.3916, 0.6084],\n",
      "        [0.4475, 0.5525],\n",
      "        [0.4657, 0.5343]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(5, device='cuda:0')\n",
      "tensor([[0.3694, 0.6306],\n",
      "        [0.4459, 0.5541],\n",
      "        [0.4628, 0.5372],\n",
      "        [0.6806, 0.3194],\n",
      "        [0.4510, 0.5490],\n",
      "        [0.3404, 0.6596],\n",
      "        [0.7945, 0.2055]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(6, device='cuda:0')\n",
      "tensor([[0.2640, 0.7360],\n",
      "        [0.6841, 0.3159],\n",
      "        [0.6027, 0.3973],\n",
      "        [0.5632, 0.4368],\n",
      "        [0.4630, 0.5370],\n",
      "        [0.4242, 0.5758],\n",
      "        [0.3674, 0.6326]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4719, 0.5281],\n",
      "        [0.3164, 0.6836],\n",
      "        [0.4684, 0.5316],\n",
      "        [0.4067, 0.5933],\n",
      "        [0.5020, 0.4980],\n",
      "        [0.6559, 0.3441],\n",
      "        [0.5805, 0.4195]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.2165, 0.7835],\n",
      "        [0.5014, 0.4986],\n",
      "        [0.7060, 0.2940],\n",
      "        [0.5467, 0.4533],\n",
      "        [0.4001, 0.5999],\n",
      "        [0.5596, 0.4404],\n",
      "        [0.6913, 0.3087]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4557, 0.5443],\n",
      "        [0.6226, 0.3774],\n",
      "        [0.5739, 0.4261],\n",
      "        [0.4618, 0.5382],\n",
      "        [0.7256, 0.2744],\n",
      "        [0.2364, 0.7636],\n",
      "        [0.4513, 0.5487]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "tensor([[0.4144, 0.5856],\n",
      "        [0.6049, 0.3951],\n",
      "        [0.5503, 0.4497],\n",
      "        [0.6478, 0.3522],\n",
      "        [0.1219, 0.8781],\n",
      "        [0.5698, 0.4302],\n",
      "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(5, device='cuda:0')\n",
      "tensor([[0.3642, 0.6358],\n",
      "        [0.2292, 0.7708],\n",
      "        [0.7983, 0.2017],\n",
      "        [0.6581, 0.3419],\n",
      "        [0.6300, 0.3700],\n",
      "        [0.4316, 0.5684],\n",
      "        [0.2000, 0.8000]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(7, device='cuda:0')\n",
      "tensor([[0.5708, 0.4292],\n",
      "        [0.6750, 0.3250],\n",
      "        [0.6286, 0.3714],\n",
      "        [0.4272, 0.5728],\n",
      "        [0.4741, 0.5259],\n",
      "        [0.4429, 0.5571],\n",
      "        [0.4364, 0.5636]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(4, device='cuda:0')\n",
      "tensor([[0.4336, 0.5664],\n",
      "        [0.5172, 0.4828],\n",
      "        [0.6170, 0.3830],\n",
      "        [0.5095, 0.4905],\n",
      "        [0.6506, 0.3494],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.6271, 0.3729]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "score: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "Classifier_path = 'D:\\\\P300_biosemi_55\\\\Model\\\\Bio\\\\'\n",
    "classifier_list = sorted(glob.glob(Classifier_path + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "weight_list = sorted(glob.glob(Classifier_path + 'Weight\\\\*.pt'), key=os.path.getmtime, reverse=True)\n",
    "model = torch.load(classifier_list[0])\n",
    "model.load_state_dict(torch.load(weight_list[0]))\n",
    "\n",
    "# filtering bandwidth\n",
    "low, high = 0.23, 30\n",
    "\n",
    "    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs    \n",
    "    \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "            for i in range(nChannel):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "#         Epochs = Standardization(Epochs)\n",
    "        Epochs_Aver = np.mean(Epochs, axis=0)\n",
    "\n",
    "        return Epochs_Aver\n",
    "        \n",
    "def main():\n",
    "\n",
    "        root_path = \"D:\\\\VR300Data\\\\0129\\\\Minchul\\\\\"\n",
    "\n",
    "        mat_path = root_path + 'Online\\\\mat\\\\'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        score = 0\n",
    "        wrong_ans = []\n",
    "        \n",
    "        target_val = nontarget_val = 0\n",
    "        \n",
    "        for mat_file in current_list:\n",
    "            #print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            \n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, low, high, samplingFreq, order=4)\n",
    "\n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor( 0.6* samplingFreq))\n",
    "            offset = int(np.floor(0.2 * samplingFreq))\n",
    "            baseline = int(np.floor(0.8 * samplingFreq))\n",
    "            \n",
    "            ####### averaging whole epochs\n",
    "            Epochs_Aver = np.zeros((buttonNum, channelNum, epochSampleNum))\n",
    "            \n",
    "            \n",
    "            for i in np.arange(0,7):\n",
    "                Epochs_Aver[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "                \n",
    "            b=torch.Tensor(Epochs_Aver[:,:,:].reshape(7,7,180)).to(DEVICE)\n",
    "            test_output=model(b)\n",
    "            test_output[:, 1].max(dim=0)\n",
    "            print(test_output)\n",
    "            predict= test_output[:, 1].max(dim=0)[1]+1\n",
    "            \n",
    "            if int(ans) == int(predict): \n",
    "                score = score + 1\n",
    "            else:\n",
    "                wrong_ans.append(mat_file[mat_file.rfind('\\\\')+1:mat_file.rfind('_')])\n",
    "            print('order: ', ans, 'predict: ', predict)\n",
    "            \n",
    "        #print('wrong answer', wrong_ans)\n",
    "        print('score:', score/15)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "elegant-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\P300_biosemi_55\\Model\\Bio\\ZERO_Bio.pt\n",
      "tensor([[0.4631, 0.5369],\n",
      "        [0.7717, 0.2283],\n",
      "        [0.5033, 0.4967],\n",
      "        [0.8008, 0.1992],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.6751, 0.3249],\n",
      "        [0.6831, 0.3169]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  5 predict:  tensor(5, device='cuda:0')\n",
      "tensor([[0.3921, 0.6079],\n",
      "        [0.1988, 0.8012],\n",
      "        [0.5575, 0.4425],\n",
      "        [0.4478, 0.5522],\n",
      "        [0.7003, 0.2997],\n",
      "        [0.6867, 0.3133],\n",
      "        [0.8003, 0.1997]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.3364, 0.6636],\n",
      "        [0.7506, 0.2494],\n",
      "        [0.4190, 0.5810],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.6684, 0.3316],\n",
      "        [0.5455, 0.4545],\n",
      "        [0.7722, 0.2278]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4902, 0.5098],\n",
      "        [0.5622, 0.4378],\n",
      "        [0.1160, 0.8840],\n",
      "        [0.2248, 0.7752],\n",
      "        [0.7620, 0.2380],\n",
      "        [0.5052, 0.4948],\n",
      "        [0.7318, 0.2682]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.4097, 0.5903],\n",
      "        [0.4075, 0.5925],\n",
      "        [0.6418, 0.3582],\n",
      "        [0.7563, 0.2437],\n",
      "        [0.7003, 0.2997],\n",
      "        [0.4277, 0.5723],\n",
      "        [0.1812, 0.8188]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  7 predict:  tensor(7, device='cuda:0')\n",
      "tensor([[0.8376, 0.1624],\n",
      "        [0.7196, 0.2804],\n",
      "        [0.3502, 0.6498],\n",
      "        [0.6167, 0.3833],\n",
      "        [0.6383, 0.3617],\n",
      "        [0.7978, 0.2022],\n",
      "        [0.3622, 0.6378]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.3326, 0.6674],\n",
      "        [0.4266, 0.5734],\n",
      "        [0.5198, 0.4802],\n",
      "        [0.4631, 0.5369],\n",
      "        [0.4359, 0.5641],\n",
      "        [0.4305, 0.5695],\n",
      "        [0.8390, 0.1610]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.2516, 0.7484],\n",
      "        [0.6058, 0.3942],\n",
      "        [0.5711, 0.4289],\n",
      "        [0.3866, 0.6134],\n",
      "        [0.6595, 0.3405],\n",
      "        [0.6867, 0.3133],\n",
      "        [0.7913, 0.2087]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.6069, 0.3931],\n",
      "        [0.3236, 0.6763],\n",
      "        [0.6824, 0.3176],\n",
      "        [0.3638, 0.6362],\n",
      "        [0.5098, 0.4902],\n",
      "        [0.6648, 0.3352],\n",
      "        [0.6401, 0.3599]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.3125, 0.6875],\n",
      "        [0.3963, 0.6037],\n",
      "        [0.5587, 0.4413],\n",
      "        [0.6648, 0.3352],\n",
      "        [0.3402, 0.6598],\n",
      "        [0.5854, 0.4146],\n",
      "        [0.7870, 0.2130]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4480, 0.5520],\n",
      "        [0.4861, 0.5139],\n",
      "        [0.5904, 0.4096],\n",
      "        [0.5426, 0.4574],\n",
      "        [0.6649, 0.3351],\n",
      "        [0.0906, 0.9094],\n",
      "        [0.6540, 0.3460]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "tensor([[0.5193, 0.4807],\n",
      "        [0.5940, 0.4060],\n",
      "        [0.3400, 0.6600],\n",
      "        [0.6442, 0.3558],\n",
      "        [0.5519, 0.4481],\n",
      "        [0.4514, 0.5486],\n",
      "        [0.6245, 0.3755]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.3581, 0.6419],\n",
      "        [0.3945, 0.6055],\n",
      "        [0.7956, 0.2044],\n",
      "        [0.5910, 0.4090],\n",
      "        [0.6291, 0.3709],\n",
      "        [0.8205, 0.1795],\n",
      "        [0.3770, 0.6230]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4619, 0.5381],\n",
      "        [0.5532, 0.4468],\n",
      "        [0.4463, 0.5537],\n",
      "        [0.5024, 0.4976],\n",
      "        [0.6888, 0.3112],\n",
      "        [0.6932, 0.3068],\n",
      "        [0.4588, 0.5412]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.6749, 0.3251],\n",
      "        [0.7981, 0.2019],\n",
      "        [0.4557, 0.5443],\n",
      "        [0.5317, 0.4683],\n",
      "        [0.3808, 0.6192],\n",
      "        [0.1369, 0.8631],\n",
      "        [0.8334, 0.1666]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "score: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 1e-5\n",
    "# 더 천천히 모델은 분석 하는것 \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        conv1 = nn.Conv1d(7, 3, 3, 1, padding=True) # 1, 6 은 임의로 한것\n",
    "        max_pool = nn.MaxPool1d(4)\n",
    "        self.bn1 = nn.BatchNorm1d(3)\n",
    "        fc1 = nn.Linear(3*1*45, 2) # fully connected layer 1번 \n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            conv1,  # N x 7 x 180 -> N x 3 x 180\n",
    "            self.bn1,\n",
    "            nn.ReLU(),\n",
    "            max_pool,  # N x 3 x 180 -> N x 3 x 45\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            fc1,  # N x 1024 -> N x 32\n",
    "            nn.Softmax()  # 이건 분류 할때 사용 한거  out 이 1개일땐 다른거 쓰면 \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        dim = 1\n",
    "        for d in x.size()[1:]: #  N x 16 x 1 x 128\n",
    "            dim = dim * d\n",
    "            \n",
    "        x = x.view(-1, dim)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "            \n",
    "Classifier_path = 'D:\\\\P300_biosemi_55\\\\Model\\\\Bio\\\\'\n",
    "classifier_list = sorted(glob.glob(Classifier_path + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "weight_list = sorted(glob.glob(Classifier_path + 'Weight\\\\*.pt'), key=os.path.getmtime, reverse=True)\n",
    "print(classifier_list[0])\n",
    "model = torch.load(classifier_list[0])\n",
    "model.load_state_dict(torch.load(weight_list[0]))\n",
    "\n",
    "# filtering bandwidth\n",
    "low, high = 0.23, 30\n",
    "\n",
    "    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs    \n",
    "    \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "            for i in range(nChannel):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "#         Epochs = Standardization(Epochs)\n",
    "        Epochs_Aver = np.mean(Epochs, axis=0)\n",
    "\n",
    "        return Epochs_Aver\n",
    "def Balancing_DataSet(Epochs, size):\n",
    "        Epochs_New = np.zeros((size, Epochs.shape[1], Epochs.shape[2]))\n",
    "    \n",
    "        index = np.random.choice(Epochs.shape[0], size = size, replace = False)\n",
    "    \n",
    "        Epochs_New = Epochs[index, :, :]\n",
    "    \n",
    "        return Epochs_New\n",
    "def Epoching_v(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs, Num[0]]    \n",
    "def plotGraph_v(filename):\n",
    "\n",
    "\n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        channelNames = mat['channelNames']\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq']\n",
    "        samplingFreq = samplingFreq[0,0]\n",
    "        stims = mat['stims']\n",
    "        channelNum = channelNames.shape\n",
    "        channelNum = channelNum[1]\n",
    "        eegData = np.transpose(eegData)\n",
    "        \n",
    "        \n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.23, 30, samplingFreq, order=4)\n",
    "    \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(0.6 * samplingFreq))\n",
    "        offset = int(np.floor(0.2 * samplingFreq)) \n",
    "        baseline = int(np.floor(0.8 * samplingFreq)) \n",
    "        [EpochsT, NumT] = Epoching_v(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching_v(eegData, stims, 0, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        EpochsN_New = Balancing_DataSet(EpochsN, NumT)\n",
    "        \n",
    "        EpochsT = Standardization(EpochsT)\n",
    "        EpochsN = Standardization(EpochsN_New)\n",
    "        Target_All=np.mean(EpochsT,axis=0)\n",
    "        \n",
    "        return [EpochsT[:,:,:], EpochsN[:,:,:]]  \n",
    "\n",
    "    \n",
    "def main():\n",
    "\n",
    "        root_path = \"D:\\\\VR300Data\\\\0129\\\\Minchul\\\\\"\n",
    "        root_VR =  'D:\\\\VR300_20\\\\S08\\\\Training\\\\mat\\\\Training.mat'\n",
    "        T_all_V= np.zeros((210,7,180))\n",
    "        N_all_V= np.zeros((210,7,180))\n",
    "        [T_all_V[:,:,:],N_all_V[:,:,:]]=plotGraph_v(root_VR)\n",
    "        Target_All=np.mean(T_all_V,axis=0)\n",
    "        mat_path = root_path + 'Online\\\\mat\\\\'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        score = 0\n",
    "        wrong_ans = []\n",
    "        \n",
    "        target_val = nontarget_val = 0\n",
    "        \n",
    "        for mat_file in current_list:\n",
    "            #print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            \n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, low, high, samplingFreq, order=4)\n",
    "\n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor( 1* samplingFreq))\n",
    "            offset = int(np.floor(0 * samplingFreq))\n",
    "            baseline = int(np.floor(1 * samplingFreq))\n",
    "            \n",
    "            ####### averaging whole epochs\n",
    "            Epochs_Aver = np.zeros((buttonNum, channelNum, epochSampleNum))\n",
    "            \n",
    "            \n",
    "            for i in np.arange(0,7):\n",
    "                Epochs_Aver[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            \n",
    "#*********************************************************\n",
    "            hz=180\n",
    "            \n",
    "            target_data = Epochs_Aver[int(ans)-1,:,:]\n",
    "            mat = np.zeros((2, hz))\n",
    "\n",
    "            for j in np.arange(0,7):\n",
    "                mat[0] = Target_All[j,:]\n",
    "                coef = np.zeros(70)\n",
    "                q=0\n",
    "                for b in np.arange(0,70):\n",
    "                    mat[1] = target_data[j,0*hz+1*b:1*hz+1*(b)]\n",
    "                    corrcoef = np.corrcoef(mat)\n",
    "                    coef[q] = corrcoef[0,1]\n",
    "                    q=q+1\n",
    "                index = np.argmax(np.abs(coef))\n",
    "            #실시간 맞춰주기\n",
    "                start = 0*hz+1*index\n",
    "                finish = 1*hz+1*(index)\n",
    "#*********************************************************   \n",
    "            '''\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            '''\n",
    "            \n",
    "            b=torch.Tensor(Epochs_Aver[:,:,start:finish].reshape(7,7,180)).to(DEVICE)\n",
    "            test_output=model(b)\n",
    "            test_output[:, 1].max(dim=0)\n",
    "            print(test_output)\n",
    "            predict= test_output[:, 1].max(dim=0)[1]+1\n",
    "            \n",
    "            if int(ans) == int(predict): \n",
    "                score = score + 1\n",
    "            else:\n",
    "                wrong_ans.append(mat_file[mat_file.rfind('\\\\')+1:mat_file.rfind('_')])\n",
    "            print('order: ', ans, 'predict: ', predict)\n",
    "            \n",
    "        #print('wrong answer', wrong_ans)\n",
    "        print('score:', score/15)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "restricted-graduation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\P300_biosemi_55\\Model\\Bio\\ZERO_Bio.pt\n",
      "tensor([[0.5925, 0.4075],\n",
      "        [0.4051, 0.5949],\n",
      "        [0.3591, 0.6409],\n",
      "        [0.5059, 0.4941],\n",
      "        [0.4667, 0.5333],\n",
      "        [0.3704, 0.6296],\n",
      "        [0.5423, 0.4577]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  5 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.5707, 0.4293],\n",
      "        [0.0443, 0.9557],\n",
      "        [0.2346, 0.7654],\n",
      "        [0.8194, 0.1806],\n",
      "        [0.7251, 0.2749],\n",
      "        [0.6464, 0.3536],\n",
      "        [0.5252, 0.4748]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.0545, 0.9455],\n",
      "        [0.7637, 0.2363],\n",
      "        [0.1479, 0.8521],\n",
      "        [0.8681, 0.1319],\n",
      "        [0.4006, 0.5994],\n",
      "        [0.7333, 0.2667],\n",
      "        [0.2141, 0.7859]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4610, 0.5390],\n",
      "        [0.1553, 0.8447],\n",
      "        [0.2183, 0.7817],\n",
      "        [0.0810, 0.9190],\n",
      "        [0.6445, 0.3555],\n",
      "        [0.7441, 0.2559],\n",
      "        [0.7203, 0.2797]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(4, device='cuda:0')\n",
      "tensor([[0.4342, 0.5658],\n",
      "        [0.4783, 0.5217],\n",
      "        [0.6211, 0.3789],\n",
      "        [0.6595, 0.3405],\n",
      "        [0.7072, 0.2928],\n",
      "        [0.5930, 0.4070],\n",
      "        [0.6308, 0.3692]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  7 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.6874, 0.3126],\n",
      "        [0.8042, 0.1958],\n",
      "        [0.5287, 0.4713],\n",
      "        [0.4937, 0.5063],\n",
      "        [0.2838, 0.7162],\n",
      "        [0.3728, 0.6272],\n",
      "        [0.3848, 0.6152]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(5, device='cuda:0')\n",
      "tensor([[8.6221e-02, 9.1378e-01],\n",
      "        [1.9452e-01, 8.0548e-01],\n",
      "        [9.4110e-02, 9.0589e-01],\n",
      "        [8.7011e-01, 1.2989e-01],\n",
      "        [1.8306e-01, 8.1694e-01],\n",
      "        [1.4091e-01, 8.5909e-01],\n",
      "        [9.9908e-01, 9.1989e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.1057, 0.8943],\n",
      "        [0.7625, 0.2375],\n",
      "        [0.6276, 0.3724],\n",
      "        [0.6290, 0.3710],\n",
      "        [0.4123, 0.5877],\n",
      "        [0.3456, 0.6544],\n",
      "        [0.2199, 0.7801]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4641, 0.5359],\n",
      "        [0.1693, 0.8307],\n",
      "        [0.4536, 0.5464],\n",
      "        [0.2887, 0.7113],\n",
      "        [0.4843, 0.5157],\n",
      "        [0.7473, 0.2527],\n",
      "        [0.6035, 0.3965]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.0098, 0.9902],\n",
      "        [0.6285, 0.3715],\n",
      "        [0.8259, 0.1741],\n",
      "        [0.4158, 0.5842],\n",
      "        [0.2133, 0.7867],\n",
      "        [0.5126, 0.4874],\n",
      "        [0.9657, 0.0343]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4020, 0.5980],\n",
      "        [0.7065, 0.2935],\n",
      "        [0.6185, 0.3815],\n",
      "        [0.3769, 0.6231],\n",
      "        [0.8628, 0.1372],\n",
      "        [0.0755, 0.9245],\n",
      "        [0.3626, 0.6374]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "tensor([[0.2999, 0.7001],\n",
      "        [0.4923, 0.5077],\n",
      "        [0.5877, 0.4123],\n",
      "        [0.8038, 0.1962],\n",
      "        [0.0105, 0.9895],\n",
      "        [0.4972, 0.5028],\n",
      "        [0.4828, 0.5172]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(5, device='cuda:0')\n",
      "tensor([[0.3002, 0.6998],\n",
      "        [0.1359, 0.8641],\n",
      "        [0.8707, 0.1293],\n",
      "        [0.6644, 0.3356],\n",
      "        [0.6244, 0.3756],\n",
      "        [0.3937, 0.6063],\n",
      "        [0.1195, 0.8805]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(7, device='cuda:0')\n",
      "tensor([[0.5831, 0.4169],\n",
      "        [0.8530, 0.1470],\n",
      "        [0.7892, 0.2108],\n",
      "        [0.4158, 0.5842],\n",
      "        [0.2678, 0.7322],\n",
      "        [0.2238, 0.7762],\n",
      "        [0.2601, 0.7399]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(6, device='cuda:0')\n",
      "tensor([[0.3602, 0.6398],\n",
      "        [0.5939, 0.4061],\n",
      "        [0.6720, 0.3280],\n",
      "        [0.4862, 0.5138],\n",
      "        [0.7886, 0.2114],\n",
      "        [0.2681, 0.7319],\n",
      "        [0.7055, 0.2945]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "score: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from EEGDataset import EEGDataset\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CNN().to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "lr = 1e-5# 더 천천히 모델은 분석 하는것 \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        conv1 = nn.Conv1d(7, 3, 3, 1, padding=True) # 1, 6 은 임의로 한것\n",
    "        max_pool = nn.MaxPool1d(4)\n",
    "        self.bn1 = nn.BatchNorm1d(3)\n",
    "        fc1 = nn.Linear(3*1*45, 2) # fully connected layer 1번 \n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            conv1,  # N x 7 x 180 -> N x 3 x 180\n",
    "            self.bn1,\n",
    "            nn.ReLU(),\n",
    "            max_pool,  # N x 3 x 180 -> N x 3 x 45\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            fc1,  # N x 1024 -> N x 32\n",
    "            nn.Softmax()  # 이건 분류 할때 사용 한거  out 이 1개일땐 다른거 쓰면 \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        dim = 1\n",
    "        for d in x.size()[1:]: #  N x 16 x 1 x 128\n",
    "            dim = dim * d\n",
    "        x = x.view(-1, dim)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "            \n",
    "Classifier_path = 'D:\\\\P300_biosemi_55\\\\Model\\\\Bio\\\\'\n",
    "classifier_list = sorted(glob.glob(Classifier_path + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "weight_list = sorted(glob.glob(Classifier_path + 'Weight\\\\*.pt'), key=os.path.getmtime, reverse=True)\n",
    "print(classifier_list[0])\n",
    "model = torch.load(classifier_list[0])\n",
    "model.load_state_dict(torch.load(weight_list[0]))\n",
    "\n",
    "# filtering bandwidth\n",
    "low, high = 0.23, 30\n",
    "\n",
    "    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs    \n",
    "    \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "            for i in range(nChannel):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "#         Epochs = Standardization(Epochs)\n",
    "        Epochs_Aver = np.mean(Epochs, axis=0)\n",
    "\n",
    "        return Epochs_Aver\n",
    "     \n",
    "def main():\n",
    "        root_path = \"D:\\\\VR300Data\\\\0129\\\\Minchul\\\\\"\n",
    "        mat_path = root_path + 'Online\\\\mat\\\\'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        score = 0\n",
    "        wrong_ans = []\n",
    "        target_val = nontarget_val = 0\n",
    "        \n",
    "        for mat_file in current_list:\n",
    "            #print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, low, high, samplingFreq, order=4)\n",
    "\n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor( 0.6* samplingFreq))\n",
    "            offset = int(np.floor(0.2 * samplingFreq))\n",
    "            baseline = int(np.floor(0.8 * samplingFreq))\n",
    "            \n",
    "            ####### averaging whole epochs\n",
    "            Epochs_Aver = np.zeros((buttonNum, channelNum, epochSampleNum))\n",
    "            \n",
    "            \n",
    "            for i in np.arange(0,7):\n",
    "                Epochs_Aver[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "#######여기 라벨을 붙여주는곳\n",
    "            target_data = np.zeros((1, 7, 180))\n",
    "            non_target_data = np.zeros((6, 7, 180))\n",
    "            B=0\n",
    "            for i in np.arange(0,7):\n",
    "                if i==int(ans)-1:\n",
    "                    target_data=Epochs_Aver[i,:,:].reshape(1,7,180)\n",
    "                else:\n",
    "                    non_target_data[B,:,:]=Epochs_Aver[i,:,:].reshape(1,7,180)\n",
    "                    B=B+1\n",
    "            X_train = np.concatenate([target_data, non_target_data])\n",
    "            y_train = np.concatenate([np.ones(target_data.shape[0]), np.zeros(non_target_data.shape[0])])\n",
    "###############################        \n",
    "            train_loader = DataLoader(\n",
    "                EEGDataset(X_train, y_train), \n",
    "                batch_size=4, \n",
    "                shuffle=True)\n",
    "    \n",
    "            for i, data in enumerate(train_loader):\n",
    "                data, label = data['data'].float().to(DEVICE), data['labels'].float().to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            model_save='D:/P300_biosemi_55/Model/CorrX/BackP.pt'\n",
    "            torch.save(model, model_save)\n",
    "            model.eval()\n",
    "                \n",
    "            Classifier_path_B = 'D:\\\\P300_biosemi_55\\\\Model\\\\CorrX\\\\'\n",
    "            classifier_list_B = sorted(glob.glob(Classifier_path_B + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "            model_B = torch.load(classifier_list_B[0])\n",
    "            b=torch.Tensor(Epochs_Aver[:,:,:].reshape(7,7,180)).to(DEVICE)\n",
    "            test_output=model_B(b)\n",
    "            test_output[:, 1].max(dim=0)\n",
    "            print(test_output)\n",
    "            predict= test_output[:, 1].max(dim=0)[1]+1\n",
    "            \n",
    "            if int(ans) == int(predict): \n",
    "                score = score + 1\n",
    "            else:\n",
    "                wrong_ans.append(mat_file[mat_file.rfind('\\\\')+1:mat_file.rfind('_')])\n",
    "            print('order: ', ans, 'predict: ', predict)\n",
    "            \n",
    "        #print('wrong answer', wrong_ans)\n",
    "        print('score:', score/15)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consolidated-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\P300_biosemi_55\\Model\\Bio\\ZERO_Bio.pt\n",
      "tensor([[0.4631, 0.5369],\n",
      "        [0.7717, 0.2283],\n",
      "        [0.5033, 0.4967],\n",
      "        [0.8008, 0.1992],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.6751, 0.3249],\n",
      "        [0.6831, 0.3169]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  5 predict:  tensor(5, device='cuda:0')\n",
      "tensor([[0.2417, 0.7583],\n",
      "        [0.0403, 0.9597],\n",
      "        [0.6188, 0.3812],\n",
      "        [0.3729, 0.6271],\n",
      "        [0.8504, 0.1496],\n",
      "        [0.8265, 0.1735],\n",
      "        [0.9504, 0.0496]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.1675, 0.8325],\n",
      "        [0.8793, 0.1207],\n",
      "        [0.3389, 0.6611],\n",
      "        [0.5476, 0.4524],\n",
      "        [0.7309, 0.2691],\n",
      "        [0.5872, 0.4128],\n",
      "        [0.9079, 0.0921]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4812, 0.5188],\n",
      "        [0.6098, 0.3902],\n",
      "        [0.0138, 0.9862],\n",
      "        [0.0608, 0.9392],\n",
      "        [0.8856, 0.1144],\n",
      "        [0.5101, 0.4899],\n",
      "        [0.8807, 0.1193]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.3158, 0.6842],\n",
      "        [0.3462, 0.6538],\n",
      "        [0.7482, 0.2518],\n",
      "        [0.8798, 0.1202],\n",
      "        [0.8232, 0.1768],\n",
      "        [0.3544, 0.6456],\n",
      "        [0.0456, 0.9544]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  7 predict:  tensor(7, device='cuda:0')\n",
      "tensor([[0.9563, 0.0437],\n",
      "        [0.8432, 0.1568],\n",
      "        [0.2092, 0.7908],\n",
      "        [0.7063, 0.2937],\n",
      "        [0.7920, 0.2080],\n",
      "        [0.9231, 0.0769],\n",
      "        [0.2396, 0.7604]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[4.7195e-02, 9.5280e-01],\n",
      "        [2.5058e-01, 7.4942e-01],\n",
      "        [1.6422e-01, 8.3578e-01],\n",
      "        [3.9724e-01, 6.0276e-01],\n",
      "        [9.8880e-02, 9.0112e-01],\n",
      "        [1.6551e-01, 8.3449e-01],\n",
      "        [9.9952e-01, 4.8064e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.0663, 0.9337],\n",
      "        [0.7318, 0.2682],\n",
      "        [0.6546, 0.3454],\n",
      "        [0.2533, 0.7467],\n",
      "        [0.7195, 0.2805],\n",
      "        [0.8265, 0.1735],\n",
      "        [0.9071, 0.0929]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.6868, 0.3132],\n",
      "        [0.1573, 0.8427],\n",
      "        [0.8332, 0.1668],\n",
      "        [0.2395, 0.7605],\n",
      "        [0.4742, 0.5258],\n",
      "        [0.7282, 0.2718],\n",
      "        [0.7140, 0.2860]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.0360, 0.9640],\n",
      "        [0.1628, 0.8372],\n",
      "        [0.4320, 0.5680],\n",
      "        [0.6675, 0.3325],\n",
      "        [0.0741, 0.9259],\n",
      "        [0.6676, 0.3324],\n",
      "        [0.9815, 0.0185]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.3482, 0.6518],\n",
      "        [0.4556, 0.5444],\n",
      "        [0.6506, 0.3494],\n",
      "        [0.5997, 0.4003],\n",
      "        [0.8155, 0.1845],\n",
      "        [0.0057, 0.9943],\n",
      "        [0.7835, 0.2165]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "tensor([[0.5126, 0.4874],\n",
      "        [0.7575, 0.2425],\n",
      "        [0.2118, 0.7882],\n",
      "        [0.8201, 0.1799],\n",
      "        [0.6839, 0.3161],\n",
      "        [0.4074, 0.5926],\n",
      "        [0.8045, 0.1955]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.2716, 0.7284],\n",
      "        [0.2937, 0.7063],\n",
      "        [0.8634, 0.1366],\n",
      "        [0.5613, 0.4387],\n",
      "        [0.6757, 0.3243],\n",
      "        [0.8908, 0.1092],\n",
      "        [0.2812, 0.7188]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.3182, 0.6818],\n",
      "        [0.6024, 0.3976],\n",
      "        [0.3067, 0.6933],\n",
      "        [0.8519, 0.1481],\n",
      "        [0.9128, 0.0872],\n",
      "        [0.8760, 0.1240],\n",
      "        [0.3597, 0.6403]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.8290, 0.1710],\n",
      "        [0.9464, 0.0536],\n",
      "        [0.4137, 0.5863],\n",
      "        [0.5660, 0.4340],\n",
      "        [0.2596, 0.7404],\n",
      "        [0.0159, 0.9841],\n",
      "        [0.9582, 0.0418]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "score: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from EEGDataset import EEGDataset\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 1e-5\n",
    "# 더 천천히 모델은 분석 하는것 \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        conv1 = nn.Conv1d(7, 3, 3, 1, padding=True) # 1, 6 은 임의로 한것\n",
    "        max_pool = nn.MaxPool1d(4)\n",
    "        self.bn1 = nn.BatchNorm1d(3)\n",
    "        fc1 = nn.Linear(3*1*45, 2) # fully connected layer 1번 \n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            conv1,  # N x 7 x 180 -> N x 3 x 180\n",
    "            self.bn1,\n",
    "            nn.ReLU(),\n",
    "            max_pool,  # N x 3 x 180 -> N x 3 x 45\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            fc1,  # N x 1024 -> N x 32\n",
    "            nn.Softmax()  # 이건 분류 할때 사용 한거  out 이 1개일땐 다른거 쓰면 \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        dim = 1\n",
    "        for d in x.size()[1:]: #  N x 16 x 1 x 128\n",
    "            dim = dim * d\n",
    "            \n",
    "        x = x.view(-1, dim)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "            \n",
    "Classifier_path = 'D:\\\\P300_biosemi_55\\\\Model\\\\Bio\\\\'\n",
    "classifier_list = sorted(glob.glob(Classifier_path + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "weight_list = sorted(glob.glob(Classifier_path + 'Weight\\\\*.pt'), key=os.path.getmtime, reverse=True)\n",
    "print(classifier_list[0])\n",
    "model = torch.load(classifier_list[0])\n",
    "model.load_state_dict(torch.load(weight_list[0]))\n",
    "\n",
    "# filtering bandwidth\n",
    "low, high = 0.23, 30\n",
    "\n",
    "    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs    \n",
    "    \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "            for i in range(nChannel):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "#         Epochs = Standardization(Epochs)\n",
    "        Epochs_Aver = np.mean(Epochs, axis=0)\n",
    "\n",
    "        return Epochs_Aver\n",
    "def Balancing_DataSet(Epochs, size):\n",
    "        Epochs_New = np.zeros((size, Epochs.shape[1], Epochs.shape[2]))\n",
    "    \n",
    "        index = np.random.choice(Epochs.shape[0], size = size, replace = False)\n",
    "    \n",
    "        Epochs_New = Epochs[index, :, :]\n",
    "    \n",
    "        return Epochs_New\n",
    "def Epoching_v(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs, Num[0]]    \n",
    "def plotGraph_v(filename):\n",
    "\n",
    "\n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        channelNames = mat['channelNames']\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq']\n",
    "        samplingFreq = samplingFreq[0,0]\n",
    "        stims = mat['stims']\n",
    "        channelNum = channelNames.shape\n",
    "        channelNum = channelNum[1]\n",
    "        eegData = np.transpose(eegData)\n",
    "        \n",
    "        \n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.23, 30, samplingFreq, order=4)\n",
    "    \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(0.6 * samplingFreq))\n",
    "        offset = int(np.floor(0.2 * samplingFreq)) \n",
    "        baseline = int(np.floor(0.8 * samplingFreq)) \n",
    "        [EpochsT, NumT] = Epoching_v(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching_v(eegData, stims, 0, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        EpochsN_New = Balancing_DataSet(EpochsN, NumT)\n",
    "        \n",
    "        EpochsT = Standardization(EpochsT)\n",
    "        EpochsN = Standardization(EpochsN_New)\n",
    "        Target_All=np.mean(EpochsT,axis=0)\n",
    "        \n",
    "        return [EpochsT[:,:,:], EpochsN[:,:,:]]  \n",
    "\n",
    "    \n",
    "def main():\n",
    "\n",
    "        root_path = \"D:\\\\VR300Data\\\\0129\\\\Minchul\\\\\"\n",
    "        root_VR =  'D:\\\\VR300_20\\\\S08\\\\Training\\\\mat\\\\Training.mat'\n",
    "        T_all_V= np.zeros((210,7,180))\n",
    "        N_all_V= np.zeros((210,7,180))\n",
    "        [T_all_V[:,:,:],N_all_V[:,:,:]]=plotGraph_v(root_VR)\n",
    "        Target_All=np.mean(T_all_V,axis=0)\n",
    "        mat_path = root_path + 'Online\\\\mat\\\\'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        score = 0\n",
    "        wrong_ans = []\n",
    "        \n",
    "        target_val = nontarget_val = 0\n",
    "        \n",
    "        for mat_file in current_list:\n",
    "            #print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            \n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, low, high, samplingFreq, order=4)\n",
    "\n",
    "            #Epoching\n",
    "            epochSampleNum_B = int(np.floor( 0.6* samplingFreq))\n",
    "            offset_B = int(np.floor(0.2 * samplingFreq))\n",
    "            baseline_B = int(np.floor(0.8 * samplingFreq))\n",
    "            \n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor( 1* samplingFreq))\n",
    "            offset = int(np.floor(0 * samplingFreq))\n",
    "            baseline = int(np.floor(1 * samplingFreq))\n",
    "                        \n",
    "            ####### averaging whole epochs\n",
    "            Epochs_Aver = np.zeros((buttonNum, channelNum, epochSampleNum))\n",
    "            Epochs_Aver_B = np.zeros((buttonNum, channelNum, epochSampleNum_B))\n",
    "            \n",
    "            for i in np.arange(0,7):\n",
    "                Epochs_Aver[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "                Epochs_Aver_B[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum_B, offset_B, baseline_B)\n",
    "#######여기 라벨을 붙여주는곳\n",
    "            target_data = np.zeros((1, 7, 180))\n",
    "            non_target_data = np.zeros((6, 7, 180))\n",
    "            B=0\n",
    "            for i in np.arange(0,7):\n",
    "                if i==int(ans)-1:\n",
    "                    target_data=Epochs_Aver_B[i,:,:].reshape(1,7,180)\n",
    "                else:\n",
    "                    non_target_data[B,:,:]=Epochs_Aver_B[i,:,:].reshape(1,7,180)\n",
    "                    B=B+1\n",
    "            X_train = np.concatenate([target_data, non_target_data])\n",
    "            y_train = np.concatenate([np.ones(target_data.shape[0]), np.zeros(non_target_data.shape[0])])\n",
    "###############################        \n",
    "            train_loader = DataLoader(\n",
    "                EEGDataset(X_train, y_train), \n",
    "                batch_size=4, \n",
    "                shuffle=True)\n",
    "    \n",
    "            for i, data in enumerate(train_loader):\n",
    "                data, label = data['data'].float().to(DEVICE), data['labels'].float().to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            model_save='D:/P300_biosemi_55/Model/CorrX/BackP.pt'\n",
    "            torch.save(model, model_save)\n",
    "            model.eval()\n",
    "                \n",
    "            Classifier_path_B = 'D:\\\\P300_biosemi_55\\\\Model\\\\CorrX\\\\'\n",
    "            classifier_list_B = sorted(glob.glob(Classifier_path_B + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "            model_B = torch.load(classifier_list_B[0])\n",
    "            \n",
    "#*********************************************************\n",
    "            hz=180\n",
    "            \n",
    "            target_data = Epochs_Aver[int(ans)-1,:,:]\n",
    "            mat = np.zeros((2, hz))\n",
    "\n",
    "            for j in np.arange(0,7):\n",
    "                mat[0] = Target_All[j,:]\n",
    "                coef = np.zeros(70)\n",
    "                q=0\n",
    "                for b in np.arange(0,70):\n",
    "                    mat[1] = target_data[j,0*hz+1*b:1*hz+1*(b)]\n",
    "                    corrcoef = np.corrcoef(mat)\n",
    "                    coef[q] = corrcoef[0,1]\n",
    "                    q=q+1\n",
    "                index = np.argmax(np.abs(coef))\n",
    "            #실시간 맞춰주기\n",
    "                start = 0*hz+1*index\n",
    "                finish = 1*hz+1*(index)\n",
    "#*********************************************************   \n",
    "            b=torch.Tensor(Epochs_Aver[:,:,start:finish].reshape(7,7,180)).to(DEVICE)\n",
    "            test_output=model_B(b)\n",
    "            test_output[:, 1].max(dim=0)\n",
    "            print(test_output)\n",
    "            predict= test_output[:, 1].max(dim=0)[1]+1\n",
    "            \n",
    "            if int(ans) == int(predict): \n",
    "                score = score + 1\n",
    "            else:\n",
    "                wrong_ans.append(mat_file[mat_file.rfind('\\\\')+1:mat_file.rfind('_')])\n",
    "            print('order: ', ans, 'predict: ', predict)\n",
    "            \n",
    "        #print('wrong answer', wrong_ans)\n",
    "        print('score:', score/15)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tough-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\P300_biosemi_55\\Model\\Bio\\ZERO_Bio.pt\n",
      "tensor([[0.4631, 0.5369],\n",
      "        [0.7717, 0.2283],\n",
      "        [0.5033, 0.4967],\n",
      "        [0.8008, 0.1992],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.6751, 0.3249],\n",
      "        [0.6831, 0.3169]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  5 predict:  tensor(5, device='cuda:0')\n",
      "tensor([[0.2444, 0.7556],\n",
      "        [0.0416, 0.9584],\n",
      "        [0.6179, 0.3821],\n",
      "        [0.3750, 0.6250],\n",
      "        [0.8472, 0.1528],\n",
      "        [0.8243, 0.1757],\n",
      "        [0.9492, 0.0508]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.1689, 0.8311],\n",
      "        [0.8759, 0.1241],\n",
      "        [0.3418, 0.6582],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.7311, 0.2689],\n",
      "        [0.5870, 0.4130],\n",
      "        [0.9056, 0.0944]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.4831, 0.5169],\n",
      "        [0.6082, 0.3918],\n",
      "        [0.0144, 0.9856],\n",
      "        [0.0621, 0.9379],\n",
      "        [0.8826, 0.1174],\n",
      "        [0.5114, 0.4886],\n",
      "        [0.8793, 0.1207]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.3171, 0.6829],\n",
      "        [0.3478, 0.6522],\n",
      "        [0.7455, 0.2545],\n",
      "        [0.8768, 0.1232],\n",
      "        [0.8205, 0.1795],\n",
      "        [0.3569, 0.6431],\n",
      "        [0.0469, 0.9531]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  7 predict:  tensor(7, device='cuda:0')\n",
      "tensor([[0.9547, 0.0453],\n",
      "        [0.8412, 0.1588],\n",
      "        [0.2123, 0.7877],\n",
      "        [0.7041, 0.2959],\n",
      "        [0.7903, 0.2097],\n",
      "        [0.9205, 0.0795],\n",
      "        [0.2414, 0.7586]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[4.9953e-02, 9.5005e-01],\n",
      "        [2.5342e-01, 7.4658e-01],\n",
      "        [1.7173e-01, 8.2827e-01],\n",
      "        [3.9845e-01, 6.0155e-01],\n",
      "        [1.0399e-01, 8.9601e-01],\n",
      "        [1.7085e-01, 8.2915e-01],\n",
      "        [9.9944e-01, 5.6065e-04]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  3 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.0680, 0.9320],\n",
      "        [0.7316, 0.2684],\n",
      "        [0.6538, 0.3462],\n",
      "        [0.2572, 0.7428],\n",
      "        [0.7178, 0.2822],\n",
      "        [0.8254, 0.1746],\n",
      "        [0.9044, 0.0956]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.6832, 0.3168],\n",
      "        [0.1586, 0.8414],\n",
      "        [0.8328, 0.1672],\n",
      "        [0.2431, 0.7569],\n",
      "        [0.4754, 0.5246],\n",
      "        [0.7255, 0.2745],\n",
      "        [0.7137, 0.2863]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(2, device='cuda:0')\n",
      "tensor([[0.0380, 0.9620],\n",
      "        [0.1652, 0.8348],\n",
      "        [0.4371, 0.5629],\n",
      "        [0.6685, 0.3315],\n",
      "        [0.0763, 0.9237],\n",
      "        [0.6674, 0.3326],\n",
      "        [0.9805, 0.0195]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  1 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.3500, 0.6500],\n",
      "        [0.4554, 0.5446],\n",
      "        [0.6459, 0.3541],\n",
      "        [0.6010, 0.3990],\n",
      "        [0.8124, 0.1876],\n",
      "        [0.0061, 0.9939],\n",
      "        [0.7798, 0.2202]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "tensor([[0.5141, 0.4859],\n",
      "        [0.7551, 0.2449],\n",
      "        [0.2139, 0.7861],\n",
      "        [0.8186, 0.1814],\n",
      "        [0.6801, 0.3199],\n",
      "        [0.4080, 0.5920],\n",
      "        [0.8020, 0.1980]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.2739, 0.7261],\n",
      "        [0.2956, 0.7044],\n",
      "        [0.8610, 0.1390],\n",
      "        [0.5619, 0.4381],\n",
      "        [0.6762, 0.3238],\n",
      "        [0.8878, 0.1122],\n",
      "        [0.2852, 0.7148]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  2 predict:  tensor(1, device='cuda:0')\n",
      "tensor([[0.3217, 0.6783],\n",
      "        [0.6025, 0.3975],\n",
      "        [0.3093, 0.6907],\n",
      "        [0.8441, 0.1559],\n",
      "        [0.9105, 0.0895],\n",
      "        [0.8745, 0.1255],\n",
      "        [0.3615, 0.6385]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  4 predict:  tensor(3, device='cuda:0')\n",
      "tensor([[0.8259, 0.1741],\n",
      "        [0.9439, 0.0561],\n",
      "        [0.4153, 0.5847],\n",
      "        [0.5646, 0.4354],\n",
      "        [0.2630, 0.7370],\n",
      "        [0.0169, 0.9831],\n",
      "        [0.9563, 0.0437]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "order:  6 predict:  tensor(6, device='cuda:0')\n",
      "score: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from EEGDataset import EEGDataset\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 1e-5\n",
    "# 더 천천히 모델은 분석 하는것 \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        conv1 = nn.Conv1d(7, 3, 3, 1, padding=True) # 1, 6 은 임의로 한것\n",
    "        max_pool = nn.MaxPool1d(4)\n",
    "        self.bn1 = nn.BatchNorm1d(3)\n",
    "        fc1 = nn.Linear(3*1*45, 2) # fully connected layer 1번 \n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            conv1,  # N x 7 x 180 -> N x 3 x 180\n",
    "            self.bn1,\n",
    "            nn.ReLU(),\n",
    "            max_pool,  # N x 3 x 180 -> N x 3 x 45\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            fc1,  # N x 1024 -> N x 32\n",
    "            nn.Softmax()  # 이건 분류 할때 사용 한거  out 이 1개일땐 다른거 쓰면 \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        dim = 1\n",
    "        for d in x.size()[1:]: #  N x 16 x 1 x 128\n",
    "            dim = dim * d\n",
    "            \n",
    "        x = x.view(-1, dim)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "            \n",
    "Classifier_path = 'D:\\\\P300_biosemi_55\\\\Model\\\\Bio\\\\'\n",
    "classifier_list = sorted(glob.glob(Classifier_path + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "weight_list = sorted(glob.glob(Classifier_path + 'Weight\\\\*.pt'), key=os.path.getmtime, reverse=True)\n",
    "print(classifier_list[0])\n",
    "model = torch.load(classifier_list[0])\n",
    "model.load_state_dict(torch.load(weight_list[0]))\n",
    "\n",
    "# filtering bandwidth\n",
    "low, high = 0.23, 30\n",
    "\n",
    "    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs    \n",
    "    \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "            for i in range(nChannel):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "#         Epochs = Standardization(Epochs)\n",
    "        Epochs_Aver = np.mean(Epochs, axis=0)\n",
    "\n",
    "        return Epochs_Aver\n",
    "def Balancing_DataSet(Epochs, size):\n",
    "        Epochs_New = np.zeros((size, Epochs.shape[1], Epochs.shape[2]))\n",
    "    \n",
    "        index = np.random.choice(Epochs.shape[0], size = size, replace = False)\n",
    "    \n",
    "        Epochs_New = Epochs[index, :, :]\n",
    "    \n",
    "        return Epochs_New\n",
    "def Epoching_v(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs, Num[0]]    \n",
    "def plotGraph_v(filename):\n",
    "\n",
    "\n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        channelNames = mat['channelNames']\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq']\n",
    "        samplingFreq = samplingFreq[0,0]\n",
    "        stims = mat['stims']\n",
    "        channelNum = channelNames.shape\n",
    "        channelNum = channelNum[1]\n",
    "        eegData = np.transpose(eegData)\n",
    "        \n",
    "        \n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.23, 30, samplingFreq, order=4)\n",
    "    \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(0.6 * samplingFreq))\n",
    "        offset = int(np.floor(0.2 * samplingFreq)) \n",
    "        baseline = int(np.floor(0.8 * samplingFreq)) \n",
    "        [EpochsT, NumT] = Epoching_v(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching_v(eegData, stims, 0, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        EpochsN_New = Balancing_DataSet(EpochsN, NumT)\n",
    "        \n",
    "        EpochsT = Standardization(EpochsT)\n",
    "        EpochsN = Standardization(EpochsN_New)\n",
    "        Target_All=np.mean(EpochsT,axis=0)\n",
    "        \n",
    "        return [EpochsT[:,:,:], EpochsN[:,:,:]]  \n",
    "\n",
    "    \n",
    "def main():\n",
    "\n",
    "        root_path = \"D:\\\\VR300Data\\\\0129\\\\Minchul\\\\\"\n",
    "        root_VR =  'D:\\\\VR300_20\\\\S08\\\\Training\\\\mat\\\\Training.mat'\n",
    "        T_all_V= np.zeros((210,7,180))\n",
    "        N_all_V= np.zeros((210,7,180))\n",
    "        [T_all_V[:,:,:],N_all_V[:,:,:]]=plotGraph_v(root_VR)\n",
    "        Target_All=np.mean(T_all_V,axis=0)\n",
    "        mat_path = root_path + 'Online\\\\mat\\\\'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        score = 0\n",
    "        wrong_ans = []\n",
    "        \n",
    "        target_val = nontarget_val = 0\n",
    "        \n",
    "        for mat_file in current_list:\n",
    "            #print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            \n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, low, high, samplingFreq, order=4)\n",
    "            \n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor( 1* samplingFreq))\n",
    "            offset = int(np.floor(0 * samplingFreq))\n",
    "            baseline = int(np.floor(1 * samplingFreq))\n",
    "                        \n",
    "            ####### averaging whole epochs\n",
    "            Epochs_Aver = np.zeros((buttonNum, channelNum, epochSampleNum))\n",
    "            \n",
    "            for i in np.arange(0,7):\n",
    "                Epochs_Aver[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "                \n",
    "            #******************************************\n",
    "            hz=180\n",
    "            \n",
    "            target_data = Epochs_Aver[int(ans)-1,:,:]\n",
    "            mat = np.zeros((2, hz))\n",
    "\n",
    "            for j in np.arange(0,7):\n",
    "                mat[0] = Target_All[j,:]\n",
    "                coef = np.zeros(70)\n",
    "                q=0\n",
    "                for b in np.arange(0,70):\n",
    "                    mat[1] = target_data[j,0*hz+1*b:1*hz+1*(b)]\n",
    "                    corrcoef = np.corrcoef(mat)\n",
    "                    coef[q] = corrcoef[0,1]\n",
    "                    q=q+1\n",
    "                index = np.argmax(np.abs(coef))\n",
    "            #실시간 맞춰주기\n",
    "                start = 0*hz+1*index\n",
    "                finish = 1*hz+1*(index)\n",
    "#********************************************************* \n",
    "                \n",
    "#######여기 라벨을 붙여주는곳\n",
    "            target_data = np.zeros((1, 7, 180))\n",
    "            non_target_data = np.zeros((6, 7, 180))\n",
    "            B=0\n",
    "            for i in np.arange(0,7):\n",
    "                if i==int(ans)-1:\n",
    "                    target_data=Epochs_Aver[i,:,start:finish].reshape(1,7,180)\n",
    "                else:\n",
    "                    non_target_data[B,:,:]=Epochs_Aver[i,:,start:finish].reshape(1,7,180)\n",
    "                    B=B+1\n",
    "            X_train = np.concatenate([target_data, non_target_data])\n",
    "            y_train = np.concatenate([np.ones(target_data.shape[0]), np.zeros(non_target_data.shape[0])])\n",
    "###############################        \n",
    "            train_loader = DataLoader(\n",
    "                EEGDataset(X_train, y_train), \n",
    "                batch_size=4, \n",
    "                shuffle=True)\n",
    "    \n",
    "            for i, data in enumerate(train_loader):\n",
    "                data, label = data['data'].float().to(DEVICE), data['labels'].float().to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            model_save='D:/P300_biosemi_55/Model/CorrX/BackP.pt'\n",
    "            torch.save(model, model_save)\n",
    "            model.eval()\n",
    "                \n",
    "            Classifier_path_B = 'D:\\\\P300_biosemi_55\\\\Model\\\\CorrX\\\\'\n",
    "            classifier_list_B = sorted(glob.glob(Classifier_path_B + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "            model_B = torch.load(classifier_list_B[0])\n",
    "            \n",
    "\n",
    "            b=torch.Tensor(Epochs_Aver[:,:,start:finish].reshape(7,7,180)).to(DEVICE)\n",
    "            test_output=model_B(b)\n",
    "            test_output[:, 1].max(dim=0)\n",
    "            print(test_output)\n",
    "            predict= test_output[:, 1].max(dim=0)[1]+1\n",
    "            \n",
    "            if int(ans) == int(predict): \n",
    "                score = score + 1\n",
    "            else:\n",
    "                wrong_ans.append(mat_file[mat_file.rfind('\\\\')+1:mat_file.rfind('_')])\n",
    "            print('order: ', ans, 'predict: ', predict)\n",
    "            \n",
    "        #print('wrong answer', wrong_ans)\n",
    "        print('score:', score/15)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "broad-verse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_label [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n",
      "1 score: 0.5641025641025641\n",
      "ans_label [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "2 score: 0.4\n",
      "ans_label [0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n",
      "3 score: 0.3684210526315789\n",
      "ans_label [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "4 score: 0.43333333333333335\n",
      "ans_label [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "5 score: 0.4666666666666667\n",
      "ans_label [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "6 score: 0.7\n",
      "ans_label [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "8 score: 1.0\n",
      "ans_label [0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "9 score: 0.5666666666666667\n",
      "ans_label [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1]\n",
      "10 score: 0.6333333333333333\n",
      "ans_label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "11 score: 0.4666666666666667\n",
      "ans_label [0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
      "14 score: 0.4666666666666667\n",
      "ans_label [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "15 score: 0.5333333333333333\n",
      "ans_label [1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "16 score: 0.43333333333333335\n",
      "ans_label [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1]\n",
      "17 score: 0.8\n",
      "ans_label [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "18 score: 0.5333333333333333\n",
      "ans_label [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "19 score: 1.0\n",
      "ans_label [1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "20 score: 0.7333333333333333\n",
      "0.6997435897435897\n",
      "[[0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0], [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0], [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0], [0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0], [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1], [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]]\n",
      "     1   2   3   4   5   6   7   8   9   10  ...  21  22  23  24  25  26  27  \\\n",
      "S01   0   0   1   1   1   1   1   1   1   0  ...   1   1   1   1   1   0   1   \n",
      "S02   0   0   0   0   1   1   1   0   1   0  ...   0   0   1   1   1   0   0   \n",
      "S03   0   1   0   0   1   0   1   1   1   0  ...   0   0   1   0   1   0   1   \n",
      "S04   1   1   0   1   0   1   0   1   1   1  ...   1   0   0   1   1   0   1   \n",
      "S05   0   0   0   1   0   1   1   1   0   0  ...   1   1   0   0   0   1   0   \n",
      "S06   1   1   1   1   1   1   1   1   1   1  ...   1   0   1   1   0   1   1   \n",
      "S08   1   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   1   1   1   \n",
      "S09   0   0   0   0   1   1   1   0   1   1  ...   1   1   0   1   0   0   0   \n",
      "S10   1   0   0   1   1   0   1   1   0   1  ...   1   1   1   0   1   1   0   \n",
      "S11   0   0   0   0   0   1   1   0   0   0  ...   0   1   1   1   1   1   0   \n",
      "S14   0   0   1   1   1   0   1   0   1   0  ...   1   0   0   0   1   0   1   \n",
      "S15   1   0   0   1   1   0   0   0   1   0  ...   0   1   1   1   1   1   1   \n",
      "S16   1   0   1   0   0   1   1   0   0   0  ...   0   0   0   1   0   0   1   \n",
      "S17   1   1   1   1   0   1   1   1   1   1  ...   1   1   0   0   1   0   1   \n",
      "S18   0   1   0   0   1   0   1   0   1   0  ...   0   0   0   1   1   0   1   \n",
      "S19   1   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   1   1   1   \n",
      "S20   1   1   0   1   1   1   0   0   1   1  ...   0   1   1   1   1   1   1   \n",
      "\n",
      "     28  29  30  \n",
      "S01   0   0   0  \n",
      "S02   0   0   0  \n",
      "S03   1   0   0  \n",
      "S04   0   0   0  \n",
      "S05   1   1   0  \n",
      "S06   0   0   0  \n",
      "S08   1   1   1  \n",
      "S09   0   1   0  \n",
      "S10   0   0   1  \n",
      "S11   0   1   0  \n",
      "S14   1   0   0  \n",
      "S15   1   0   1  \n",
      "S16   0   0   0  \n",
      "S17   1   1   1  \n",
      "S18   1   1   1  \n",
      "S19   1   1   1  \n",
      "S20   1   0   1  \n",
      "\n",
      "[17 rows x 30 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from pandas import DataFrame  # 데이터프레임 클래스\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "Classifier_path = 'D:\\\\P300_biosemi_55\\\\Model\\\\Bio\\\\'\n",
    "classifier_list = sorted(glob.glob(Classifier_path + '*.pt'), key=os.path.getmtime, reverse=True)\n",
    "weight_list = sorted(glob.glob(Classifier_path + 'Weight\\\\*.pt'), key=os.path.getmtime, reverse=True)\n",
    "model = torch.load(classifier_list[0])\n",
    "model.load_state_dict(torch.load(weight_list[0]))\n",
    "\n",
    "# filtering bandwidth\n",
    "low, high = 0.23, 30\n",
    "\n",
    "resampleRate = 100    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs    \n",
    "def baseline_correction(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        for j in range(Epochs.shape[0]):\n",
    "            Epochs[j,i,:] = np.subtract(Epochs[j,i,:], np.mean(Epochs[j,i,:]))\n",
    "    \n",
    "    return Epochs       \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "            for i in range(nChannel):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "        #Epochs = baseline_correction(Epochs)\n",
    "        Epochs_Aver = np.mean(Epochs, axis=0)\n",
    "\n",
    "        return Epochs_Aver\n",
    "    \n",
    "def Convert_to_FeatureVector(Epochs, buttonNum, featureNum):\n",
    "    Features = np.zeros((buttonNum, featureNum))\n",
    "    for i in range(buttonNum):\n",
    "        Features[i, :] = np.reshape(Epochs[i, :, :], (1, featureNum))\n",
    "    return Features\n",
    "\n",
    "def resampling(Epochs, resampleRate, channelNum):\n",
    "        resampled_epoch = np.zeros((channelNum, resampleRate))\n",
    "        for j in range(channelNum):\n",
    "            resampled_epoch[j,:] = signal.resample(Epochs[j,:], resampleRate)\n",
    "            \n",
    "        return resampled_epoch\n",
    "    \n",
    "def main():\n",
    "    sum=0\n",
    "    Total_Score=0.0\n",
    "    total_label =[]\n",
    "    for k in np.arange(1,21):\n",
    "        if(k==7 or k==12 or k==13):\n",
    "            continue\n",
    "        root=\"D:\\\\VR300_20\\\\S\"\n",
    "        if(k<10):\n",
    "            filename = root + '0' + str(k)\n",
    "        else:\n",
    "            filename = root + str(k)\n",
    "        #root_path = \"D:\\\\VR300_20\\\\S03\\\\\"\n",
    "\n",
    "        mat_path = filename + '\\\\Online\\\\mat\\\\'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        score = 0\n",
    "        ans_label= []\n",
    "        wrong_ans = []\n",
    "        \n",
    "        target_val = nontarget_val = 0\n",
    "        for mat_file in current_list:\n",
    "            #print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            \n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, low, high, samplingFreq, order=4)\n",
    "\n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor(0.6 * samplingFreq))\n",
    "            offset = int(np.floor(0.2 * samplingFreq))\n",
    "            baseline = int(np.floor(0.8 * samplingFreq))\n",
    "            \n",
    "            ####### averaging whole epochs\n",
    "            Epochs_Aver = np.zeros((buttonNum, channelNum, epochSampleNum))\n",
    "            Epochs_final = np.zeros((buttonNum, channelNum, resampleRate))\n",
    "            \n",
    "            featureNum = channelNum*resampleRate\n",
    "            \n",
    "            for i in range(buttonNum):\n",
    "                Epochs_Aver[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "                Epochs_final[i] = resampling(Epochs_Aver[i], resampleRate, channelNum)\n",
    "            #answer=model(Epochs_final)\n",
    "            \n",
    "            #print(Epochs_Aver.shape)\n",
    "            b=torch.Tensor(Epochs_Aver[:,:,:].reshape(7,7,180)).to(DEVICE)\n",
    "            test_output=model(b)\n",
    "            test_output[:, 1].max(dim=0)\n",
    "            #print(test_output)\n",
    "            predict= test_output[:, 1].max(dim=0)[1]+1\n",
    "            \n",
    "            if int(ans) == int(predict): \n",
    "                #ans_label.append(mat_file[mat_file.rfind('\\\\')+1:mat_file.rfind('_')])\n",
    "                if(len(ans_label)>29):\n",
    "                    continue\n",
    "                ans_label.append(1)\n",
    "                score = score + 1\n",
    "            else:\n",
    "                wrong_ans.append(mat_file[mat_file.rfind('\\\\')+1:mat_file.rfind('_')])\n",
    "                if(len(ans_label)>29):\n",
    "                    continue\n",
    "                ans_label.append(0)\n",
    "            #print('order: ', ans, 'predict: ', predict)\n",
    "        \n",
    "        print('ans_label', ans_label)\n",
    "        total_label.append(ans_label)\n",
    "        print(k,'score:', score/(len(wrong_ans)+score))\n",
    "        \n",
    "        if (k==1 or k==6 or k==8  or k==9 or k==10 or k==11 or k==15 or k==17 or k==19 or k==20):\n",
    "            sum=sum+ score/(len(wrong_ans)+score)\n",
    "    print(sum/10)\n",
    "    print(total_label)\n",
    "    df = pd.DataFrame(total_label,\n",
    "                   index=['S01','S02','S03','S04','S05','S06','S08','S09','S10','S11','S14','S15','S16','S17','S18','S19','S20'],\n",
    "                   columns=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30])\n",
    "    print(df)\n",
    "# heatmap by plt.pcolor()\n",
    "\n",
    "    for i in range(df.shape[1]):\n",
    "        for j in range(df.shape[0]):\n",
    "            if round(df.iloc[j,i],2) == 1:\n",
    "                plt.text(i+0.5,j+0.5,'o',ha='center',va='center')\n",
    "            else:\n",
    "                plt.text(i+0.5,j+0.5,'x',ha='center',va='center')\n",
    "\n",
    "    sns.heatmap(df, cmap='Blues_r')\n",
    "    plt.title('Correlation+VR300', fontsize=20)\n",
    "    plt.xlabel('Online_Session', fontsize=14)\n",
    "    plt.ylabel('Subject', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-light",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-moment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
